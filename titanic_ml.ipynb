{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "#importing numpy and pandas\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Importing training and test data\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "# Examining training data to see what transformations need to be made\n",
    "\n",
    "print(len(train_data))\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "Test\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "     PassengerId  Pclass                Name   Sex   Age  SibSp  Parch Ticket  \\\n",
      "152         1044       3  Storey, Mr. Thomas  male  60.5      0      0   3701   \n",
      "\n",
      "     Fare Cabin Embarked  \n",
      "152   NaN   NaN        S  \n",
      "Train\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "\n",
      "Test\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for null values\n",
    "\n",
    "print('Train')\n",
    "print(train_data.isnull().sum())\n",
    "print('\\nTest')\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "\n",
    "# Null values in Age, Cabin and Embarked\n",
    "\n",
    "# Replacing null values in \"Age\" with mean age\n",
    "\n",
    "mean_age = train_data.Age.mean()\n",
    "test_mean_age = test_data.Age.mean()\n",
    "\n",
    "train_data.Age.fillna(mean_age, inplace=True)\n",
    "test_data.Age.fillna(test_mean_age, inplace=True)\n",
    "\n",
    "# Removing records from train with Null values in \"Embarked\"\n",
    "\n",
    "train_data.dropna(subset=['Embarked'], inplace=True)\n",
    "\n",
    "# Identifying test record with missing fare\n",
    "\n",
    "print(test_data[test_data['Fare'].isnull()])\n",
    "\n",
    "# Passenger is in 3rd Class and embarked at Southampton; finding mean fare for 3rd class Southampton passengers\n",
    "\n",
    "third_class_mean = test_data[(test_data['Pclass'] == 3) & (test_data['Embarked'] == 'S')].Fare.mean()\n",
    "\n",
    "test_data.Fare.fillna(third_class_mean, inplace=True)\n",
    "\n",
    "#Final check for null values (Ignoring \"Cabin\" null values as there are too many to drop and nothing clear to fill with)\n",
    "\n",
    "print('Train')\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "print('\\nTest')\n",
    "print(test_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name  Sex        Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    0  22.000000      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.000000      1   \n",
      "2                             Heikkinen, Miss. Laina    1  26.000000      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.000000      1   \n",
      "4                           Allen, Mr. William Henry    0  35.000000      0   \n",
      "5                                   Moran, Mr. James    0  29.699118      0   \n",
      "6                            McCarthy, Mr. Timothy J    0  54.000000      0   \n",
      "7                     Palsson, Master. Gosta Leonard    0   2.000000      3   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)    1  27.000000      0   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)    1  14.000000      1   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  qvs  qvc  p2vp1  p2vp3  \n",
      "0      0         A/5 21171   7.2500   NaN        S    1    0      0      1  \n",
      "1      0          PC 17599  71.2833   C85        C    0    1      1      0  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S    1    0      0      1  \n",
      "3      0            113803  53.1000  C123        S    1    0      1      0  \n",
      "4      0            373450   8.0500   NaN        S    1    0      0      1  \n",
      "5      0            330877   8.4583   NaN        Q    0    0      0      1  \n",
      "6      0             17463  51.8625   E46        S    1    0      1      0  \n",
      "7      1            349909  21.0750   NaN        S    1    0      0      1  \n",
      "8      2            347742  11.1333   NaN        S    1    0      0      1  \n",
      "9      0            237736  30.0708   NaN        C    0    1      0      0  \n"
     ]
    }
   ],
   "source": [
    "#\"Sex\" and \"Embarked\" contain non-numerical values\n",
    "# Giving numerical representations of \"Sex\"\n",
    "\n",
    "train_data['Sex'] = train_data['Sex'].apply(lambda x: 0 if x == \"male\" else 1)\n",
    "\n",
    "\n",
    "# Coding dummy variables for numerical representations of point of Embarkation\n",
    "\n",
    "train_data['qvs'] = train_data['Embarked'].apply(lambda x: 1 if x == 'S' else 0)\n",
    "train_data['qvc'] = train_data['Embarked'].apply(lambda x: 1 if x == 'C' else 0)\n",
    "\n",
    "\n",
    "# Coding dummy variables for Passenger Class\n",
    "\n",
    "train_data['p2vp1'] = train_data['Pclass'].apply(lambda x: 1 if x == 1 else 0)\n",
    "train_data['p2vp3'] = train_data['Pclass'].apply(lambda x: 1 if x == 3 else 0)\n",
    "\n",
    "print(train_data.head(10))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   p2vp1  p2vp3  Sex   Age  SibSp  Parch     Fare  qvs  qvc\n",
      "0      0      1    0  22.0      1      0   7.2500    1    0\n",
      "1      1      0    1  38.0      1      0  71.2833    0    1\n",
      "2      0      1    1  26.0      0      0   7.9250    1    0\n",
      "3      1      0    1  35.0      1      0  53.1000    1    0\n",
      "4      0      1    0  35.0      0      0   8.0500    1    0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Separating features from target\n",
    "\n",
    "cleaned_data = train_data[['p2vp1', 'p2vp3', 'Sex', 'Age',\\\n",
    "                           'SibSp', 'Parch', 'Fare', 'qvs', 'qvc']]\n",
    "\n",
    "target_data = train_data[['Survived']]\n",
    "target_data = target_data.iloc[:, -1].values\n",
    "\n",
    "print(cleaned_data.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.88427871e-01 -1.14177151e+00  2.61082889e+00 -3.81099701e-02\n",
      "  -3.11550001e-01 -9.02315509e-02  2.48383042e-03 -2.71093966e-01\n",
      "   1.94417792e-01]]\n",
      "0.7424071991001124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# First pass: logistic regression without scaling using Scikit-Learn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "unscaled_log_model = LogisticRegression()\n",
    "\n",
    "unscaled_log_model.fit(cleaned_data, target_data)\n",
    "\n",
    "#checking coeffs and R^2\n",
    "\n",
    "print(unscaled_log_model.coef_)\n",
    "print(unscaled_log_model.score(unit_scaled_data, target_data))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.83593194 -1.16706398  2.54829678 -2.13664842 -1.39842426 -0.40663929\n",
      "   0.48115022 -0.40100799  0.09612094]]\n",
      "0.8020247469066367\n"
     ]
    }
   ],
   "source": [
    "#Second pass: Logistic regression with unit scaling\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "unit_scaler = MinMaxScaler()\n",
    "\n",
    "unit_scaled_data = pd.DataFrame(unit_scaler.fit_transform(cleaned_data))\n",
    "\n",
    "\n",
    "# producing LR model with unit scaled data\n",
    "\n",
    "unit_scaled_log_model = LogisticRegression()\n",
    "\n",
    "unit_scaled_log_model.fit(unit_scaled_data, target_data)\n",
    "\n",
    "#checking coeffs and R^2\n",
    "\n",
    "print(unit_scaled_log_model.coef_)\n",
    "print(unit_scaled_log_model.score(unit_scaled_data, target_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.38911209 -0.60134545  1.27943211 -0.49993988 -0.34742874 -0.07490603\n",
      "   0.11410341 -0.18203823  0.01525313]]\n",
      "0.8042744656917885\n"
     ]
    }
   ],
   "source": [
    "# Third pass: Logistic regression with standardisation\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_data = pd.DataFrame(scaler.fit_transform(cleaned_data))\n",
    "\n",
    "# producing LR model with unit scaled data\n",
    "scaled_log_model = LogisticRegression()\n",
    "\n",
    "scaled_log_model.fit(scaled_data, target_data)\n",
    "\n",
    "#checking coeffs and R^2\n",
    "\n",
    "print(scaled_log_model.coef_)\n",
    "print(scaled_log_model.score(scaled_data, target_data))\n",
    "\n",
    "# Highest R^2 so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
